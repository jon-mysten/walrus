"use strict";(globalThis.webpackChunkwalrus_docusaurus=globalThis.webpackChunkwalrus_docusaurus||[]).push([[6507],{1113(e,t,n){n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});let i=JSON.parse('{"id":"design/operations-off-chain","title":"Off-Chain Operations","description":"Detailed explanation of Walrus off-chain operations including write paths, read operations, and storage node interactions.","source":"@site/../content/design/operations-off-chain.mdx","sourceDirName":"design","slug":"/design/operations-off-chain","permalink":"/docs/design/operations-off-chain","draft":false,"unlisted":false,"editUrl":"https://github.com/MystenLabs/walrus/tree/main/docs/../content/design/operations-off-chain.mdx","tags":[],"version":"current","frontMatter":{"title":"Off-Chain Operations","description":"Detailed explanation of Walrus off-chain operations including write paths, read operations, and storage node interactions.","keywords":["walrus","off-chain operations","write paths","read operations","storage nodes","slivers","availability certificate","challenge mechanism"]}}');var s=n(2615),o=n(5756);let r={title:"Off-Chain Operations",description:"Detailed explanation of Walrus off-chain operations including write paths, read operations, and storage node interactions.",keywords:["walrus","off-chain operations","write paths","read operations","storage nodes","slivers","availability certificate","challenge mechanism"]},a,l={},c=[{value:"Write operations",id:"write-operations",level:2},{value:"Acquire storage resource",id:"acquire-storage-resource",level:3},{value:"Encode and compute blob ID",id:"encode-and-compute-blob-id",level:3},{value:"Register blob ID",id:"register-blob-id",level:3},{value:"Store slivers",id:"store-slivers",level:3},{value:"Availability certificate",id:"availability-certificate",level:3},{value:"Certify blob ID",id:"certify-blob-id",level:3},{value:"Effects certificate proves availability",id:"effects-certificate-proves-availability",level:3},{value:"Read operations",id:"read-operations",level:2},{value:"Refresh availability",id:"refresh-availability",level:2},{value:"Inconsistency handling",id:"inconsistency-handling",level:2},{value:"Reading inconsistent blobs",id:"reading-inconsistent-blobs",level:3},{value:"Challenge mechanism for storage attestation",id:"challenge-mechanism-for-storage-attestation",level:2}];function d(e){let t={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components},{Term:i}=t;return i||function(e,t){throw Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Term",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(t.p,{children:["Walrus operations primarily occur off-chain on ",(0,s.jsx)(i,{lookup:"Storage node",children:"storage nodes"}),", though they interact with the ",(0,s.jsx)(t.a,{href:"https://docs.sui.io/",children:"Sui blockchain"})," for ",(0,s.jsx)(t.a,{href:"/docs/design/operations-sui",children:"resource lifecycle management"}),". This page describes the complete off-chain operations for writing, reading, and managing ",(0,s.jsx)(i,{lookup:"Blob",children:"blobs"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"write-operations",children:"Write operations"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Write paths of Walrus",src:n(6027).A+"",width:"851",height:"891"})}),"\n",(0,s.jsx)(t.h3,{id:"acquire-storage-resource",children:"Acquire storage resource"}),"\n",(0,s.jsx)(t.p,{children:"You acquire a storage resource of appropriate size and duration on-chain, either by directly buying it from the Walrus system object or a secondary market. You can split, merge, and transfer owned storage resources."}),"\n",(0,s.jsxs)(t.h3,{id:"encode-and-compute-blob-id",children:["Encode and compute ",(0,s.jsx)(i,{lookup:"Blob ID",children:"blob ID"})]}),"\n",(0,s.jsxs)(t.p,{children:["When you want to store a ","blob",", you first apply erasure coding to the ","blob",", and then compute the ","blob ID"," from the encoded data. You can then perform the remaining write flow steps yourself, or use a ",(0,s.jsx)(i,{lookup:"Publisher",children:"publisher"})," to perform the steps on your behalf."]}),"\n",(0,s.jsxs)(t.h3,{id:"register-blob-id",children:["Register ","blob ID"]}),"\n",(0,s.jsxs)(t.p,{children:["Interact with Sui to update a storage resource and register the ","blob ID"," with the desired size and lifetime. This emits an event that the Walrus ","storage nodes"," receive. The upload continues after event confirmation."]}),"\n",(0,s.jsx)(t.h3,{id:"store-slivers",children:"Store slivers"}),"\n",(0,s.jsxs)(t.p,{children:["Send the ",(0,s.jsx)(i,{lookup:"Blob metadata",children:"blob metadata"})," to all ","storage nodes",". Each of the ","blob"," slivers are sent to the ","storage node"," that currently manages the corresponding ",(0,s.jsx)(i,{lookup:"Shard",children:"shard"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"availability-certificate",children:"Availability certificate"}),"\n",(0,s.jsxs)(t.p,{children:["A ","storage node"," managing a ","shard"," receives a ",(0,s.jsx)(i,{lookup:"Sliver",children:"sliver"})," and checks it against the ","blob ID",". It also checks that there is a ","blob"," resource with the ","blob ID"," that is authorized to store a ","blob",". If correct, the ","storage node"," then signs a statement that it holds the ","sliver"," and returns it to you. Then, you can put together the signatures returned from ","storage nodes"," into an availability certificate."]}),"\n",(0,s.jsxs)(t.h3,{id:"certify-blob-id",children:["Certify ","blob ID"]}),"\n",(0,s.jsxs)(t.p,{children:["Submit an availability certificate to the chain. When the certificate is verified on-chain, an availability event for the ","blob ID"," is emitted, and all other ","storage nodes"," seek to download any missing shards for the ","blob ID",". This event emitted by Sui is the ",(0,s.jsx)(t.a,{href:"/docs/design/properties",children:"point of availability (PoA)"})," for the ","blob ID","."]}),"\n",(0,s.jsxs)(t.p,{children:["After the ",(0,s.jsx)(i,{lookup:"Point of availability",children:"PoA"}),", and without your involvement, ","storage nodes"," sync and recover any missing metadata and slivers."]}),"\n",(0,s.jsx)(t.h3,{id:"effects-certificate-proves-availability",children:"Effects certificate proves availability"}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(i,{lookup:"Certificate of availability",children:"certificate of availability"})," is created from 2/3 of the returned ","shard"," signatures. The erasure code rate is below 1/3, meaning that ",(0,s.jsx)(i,{lookup:"Reconstruction",children:"reconstruction"})," is allowed even if only 1/3 of shards return the ","sliver"," for a read. ",(0,s.jsx)(t.a,{href:"/docs/design/architecture#byzantine-fault-tolerance",children:"Because at most 1/3 of the storage nodes can fail"}),", this ensures ","reconstruction"," if you request slivers from all ","storage nodes",". A ","publisher"," can mediate the full process by receiving a ","blob"," and driving the process to completion."]}),"\n",(0,s.jsx)(t.h2,{id:"read-operations",children:"Read operations"}),"\n",(0,s.jsxs)(t.p,{children:["Reading ","blobs"," from Walrus can occur directly or through aggregators and caches. The operations are identical whether performed by end users, aggregators, or caches experiencing ",(0,s.jsx)(i,{lookup:"Cache",children:"cache"})," misses. In practice, most reads occur through caches for frequently accessed (hot) ","blobs"," and do not require requests to ","storage nodes","."]}),"\n",(0,s.jsx)(t.p,{children:"The read flow consists of the following steps:"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:["Obtain the metadata for the ","blob ID"," from any ","storage node"," and authenticate it using the ","blob ID","."]}),"\n",(0,s.jsxs)(t.li,{children:["Send a request to the ","storage nodes"," for the shards corresponding to the ","blob ID"," and wait for (f+1) responses. Send sufficient requests in parallel to ensure low latency for reads."]}),"\n",(0,s.jsxs)(t.li,{children:["Authenticate the slivers returned with the ","blob ID",", reconstruct the ","blob",", and decide whether the contents are valid or inconsistent."]}),"\n",(0,s.jsxs)(t.li,{children:["Optionally, the result is cached and can be served without ","reconstruction"," until it is evicted from the ","cache",". Requests to the ","cache"," for the ","blob"," return the ","blob"," contents or an ",(0,s.jsx)(i,{lookup:"Inconsistency proof",children:"inconsistency proof"}),"."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"refresh-availability",children:"Refresh availability"}),"\n",(0,s.jsxs)(t.p,{children:["Because no ","blob"," content is involved, refresh operations are conducted entirely through the Sui protocol. To extend ","blob"," availability, provide an appropriate on-chain storage resource. Upon success, ","storage nodes"," receive an emitted event to extend the storage duration for each ","sliver","."]}),"\n",(0,s.jsx)(t.h2,{id:"inconsistency-handling",children:"Inconsistency handling"}),"\n",(0,s.jsxs)(t.p,{children:["After the ","PoA",", a correct ","storage node"," attempting to reconstruct a ","sliver"," might fail if ","blob"," encoding was incorrect. In this case, the node can extract an ","inconsistency proof"," for the ","blob ID",". It then uses the proof to create an ",(0,s.jsx)(i,{lookup:"Inconsistency certificate",children:"inconsistency certificate"})," and uploads it on-chain."]}),"\n",(0,s.jsx)(t.p,{children:"The flow is as follows:"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:["A ","storage node"," fails to reconstruct a ","sliver",", and instead computes an ","inconsistency proof","."]}),"\n",(0,s.jsxs)(t.li,{children:["The ","storage node"," sends the ","blob ID"," and ","inconsistency proof"," to all ","storage nodes"," of the Walrus epoch. The ","storage nodes"," verify the proof and sign it."]}),"\n",(0,s.jsxs)(t.li,{children:["The ","storage node"," that found the inconsistency aggregates the signatures into an ","inconsistency certificate"," and sends it to the ",(0,s.jsx)(t.a,{href:"https://docs.sui.io/guides/developer/sui-101/move-package-management",children:"Sui smart contract"}),", which verifies it and emits an inconsistent resource event."]}),"\n",(0,s.jsxs)(t.li,{children:["Upon receiving an inconsistent resource event, correct ","storage nodes"," delete ","sliver"," data for the ","blob ID"," and record in the metadata to return ",(0,s.jsx)(t.code,{children:"None"})," for the ","blob"," during the ",(0,s.jsx)(t.a,{href:"/docs/design/properties",children:"availability period"}),". No ",(0,s.jsx)(i,{lookup:"Storage attestation",children:"storage attestation"})," challenges are issued for this ","blob ID","."]}),"\n"]}),"\n",(0,s.jsxs)(t.h3,{id:"reading-inconsistent-blobs",children:["Reading inconsistent ","blobs"]}),"\n",(0,s.jsxs)(t.p,{children:["A ","blob ID"," marked as inconsistent always resolves to ",(0,s.jsx)(t.code,{children:"None"})," upon reading. This occurs because the read process re-encodes the received ","blob"," to verify that the ","blob ID"," was derived from consistent encoding."]}),"\n",(0,s.jsxs)(t.p,{children:["An ","inconsistency proof"," reveals only a true fact to ","storage nodes"," (which do not otherwise run decoding) and does not change read output in any case."]}),"\n",(0,s.jsx)(t.p,{children:"However, partial reads leveraging the systematic nature of the encoding might successfully return partial data for inconsistently encoded files. If consistency and availability of reads is important, perform full reads rather than partial reads."}),"\n",(0,s.jsxs)(t.h2,{id:"challenge-mechanism-for-storage-attestation",children:["Challenge mechanism for ","storage attestation"]}),"\n",(0,s.jsxs)(t.p,{children:["During an epoch, a correct ","storage node"," challenges all shards to provide symbols for ","blob"," slivers past ","PoA",":"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["The list of available ","blobs"," for the epoch is determined by the sequence of Sui events up to the past epoch. Inconsistent ","blobs"," are not challenged, and a record proving this status can be returned instead."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["A challenge sequence is determined by providing a seed to the challenged ","shard",". The sequence is then computed based on the seed ",(0,s.jsx)(t.strong,{children:"and"})," the content of each challenged ","blob ID",". This creates a sequential read dependency."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsxs)(t.p,{children:["The response to the challenge provides the sequence of ","shard"," contents for the ","blob"," IDs in a timely manner."]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The challenger node uses thresholds to determine whether the challenge was passed, and reports the result on-chain."}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:["\n",(0,s.jsx)(t.p,{children:"The challenge and response communication is authenticated."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["Challenges provide some reassurance that the ","storage node"," can actually recover ","shard"," data in a probabilistic manner, avoiding ","storage nodes"," getting payment without any evidence they might retrieve ","shard"," data. The sequential nature of the challenge and some reasonable timeout also ensures that the process is timely."]})]})}function h(e={}){let{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},5756(e,t,n){n.d(t,{R:()=>r,x:()=>a});var i=n(9471);let s={},o=i.createContext(s);function r(e){let t=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(o.Provider,{value:t},e.children)}},6027(e,t,n){n.d(t,{A:()=>i});let i=n.p+"assets/images/WriteFlow-a5c02d29e5afa38d8ef342e961f7404c.png"}}]);